{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Week 5: A.2 Second Research/Programming Assignment\n",
    "#Due No Due Date Points 100 Submitting a file upload File Types zip, pdf, py, txt, ipynb, and html\n",
    "#This assignment concerns vectorization and document classification.\n",
    "\n",
    "#In this assignment, you can continue to work with your individual corpus or work with a corpus \n",
    "#that you identify from the course or available public-domain sources. The Reduced Reuters Corpus may not \n",
    "#be used for this assignment because extensive jump-start code is provided for that corpus. \n",
    "#The corpus should have between two and ten identified classes of documents so that document \n",
    "#classification can be performed as the final step of the study. \n",
    "#The class of a document could be defined by the document source, with a known external variable, \n",
    "#or with a variable that you, the analyst, define. It could be a subtopic within \n",
    "#the general topic of interest used to define the corpus.\n",
    "\n",
    "#Consider three methods for assigning numerical vectors to documents. \n",
    "#For each method, obtain a vector of numbers representing each document in the corpus. \n",
    "#Represent these as row vectors, creating a documents-by-terms matrix for each vectorization method. \n",
    "#We refer to the columns as \"terms,\" but, depending on the method being employed, \n",
    "#these could be individual words, n-grams, tokens, or (as is the case for Doc2Vec) index positions along a vector.\n",
    "\n",
    "#Approach 1: Analyst Judgment.\n",
    "#As we have reviewed in classroom discussions, initial work with document collections could begin \n",
    "#with identifying important terms or equivalence classes (ECs) to be included \n",
    "#in a corpus-wide Reference Term Vector (RTV). \n",
    "#One way to do this is to employ analyst judgment guided by corpus statistics. \n",
    "\n",
    "#To decide on whether or not we will keep a term in a small document collection, \n",
    "#for example, we need to know that: (1) It is important in at least one document, \n",
    "#and (2) It is prevalent in more than one document.\n",
    "\n",
    "#For larger document collections, we may specify percentages of documents \n",
    "#in which we observe the terms or ECs. Analyst judgment is critical to this approach.\n",
    "\n",
    "#After the important terms have been identified, we can assign a number (perhaps a count or proportion) \n",
    "#for each term in each document. That is, we can define a vector of numbers for each document.\n",
    "\n",
    "#Approach 2: TF-IDF.\n",
    "\n",
    "#Identify the top terms by corpus-wide statistics (TF-IDF, in particular). \n",
    "#Regarding TF-IDF, we can compute the TF-IDF for each extracted term across the entire corpus. \n",
    "#For our reference vector, we can choose a subset of terms with the highest TF-IDF values across the corpus. \n",
    "#A high TF-IDF means that the term is both prevalent (across the corpus) \n",
    "#and prominent (within at least one or more documents). Additionally, \n",
    "#we have the TF-IDF value for each term within each document. \n",
    "#Python Scikit Learn provides TF-IDF vectorization:\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html \n",
    "\n",
    "\n",
    "#Approach 3: Neural Network Embeddings (Doc2Vec).\n",
    "\n",
    "#With this approach, we utilize machine learning methods to convert documents to vectors of numbers. \n",
    "#Such methods draw on self-supervised machine learning (autoencoding a la Word2Vec). \n",
    "#Instead of Word2Vec, however, we use Doc2Vec, representing each document with a set of numbers. \n",
    "#The numbers come from neural network weights or embeddings. The numbers are not directly associated \n",
    "#with terms, so the meaning of the numbers is undefined. Python Gensim provides Doc2Vec vectorizations:\n",
    "\n",
    "#https://radimrehurek.com/gensim/models/doc2vec.html (Links to an external site.)\n",
    "\n",
    "#Management Problem. Part of your job in this assignment is to define a meaningful management problem. \n",
    "#The corpus you use should relate in some way to a business, organizational, \n",
    "#or societal problem. Regardless of the neural network methods being employed, \n",
    "#research results should provide guidance in addressing the management problem. \n",
    "\n",
    "#Research Methods/Programming Components\n",
    "\n",
    "#This research/programming assignment involves ten activities as follows:\n",
    "\n",
    "#(1) Define a management goal for your research. What do you hope to learn \n",
    "#    from this natural language study? What management questions will be addressed? \n",
    "#     Consider a goal related to document classification.\n",
    "#(2) Identify the individual corpus you will be using in the assignment. \n",
    "#     The corpus should be available as a JSON lines file. \n",
    "#     Previously, we had suggested that the JSON lines file be set up with at \n",
    "#     least four key-value pairs defined as \"ID,\" \"URL,\" \"TITLE,\", and \"BODY,\" \n",
    "#     where \"BODY\" represents a plain text document. To facilitate subsequent analyses, \n",
    "#     it may be convenient to use a short character string (say, eight characters or less) \n",
    "#     to identify each document. This short character string could be the value associated \n",
    "#     with the ID key or with an additional key that you define. \n",
    "#(3) Preprocess the text documents, ensuring that unnecessary tags, \n",
    "#    punctuation, and images are excluded.  \n",
    "#(4) Create document vectors using Approach 1 above.\n",
    "#(5) Create document vectors using Approach 2 above.\n",
    "#(6) Create document vectors using Approach 3 above.\n",
    "#(7) Compare results across the three approaches. \n",
    "#     In comparing Approach 1 with Approach 2, for example, \n",
    "#     find the two or three terms (nouns/noun phrases) \n",
    "#     from your documents that you thought to be important/prevalent \n",
    "#     from Approach 1 and see if they did indeed have the highest TF-IDF as shown \n",
    "#     in the results from Approach 2. Similarly, find two or three terms that \n",
    "#     you thought would have a lower importance/prevalence, and see if that bears out. \n",
    "#     Judge the degree of agreement across the approaches.\n",
    "#(8) Review results in light of the management goal for this research. \n",
    "#     Do you have concerns about the corpus? Are there ways that the corpus should be extended \n",
    "#     or contracted in order to address management questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".output {\n",
       "    flex-direction: row;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import glob\n",
    "from nltk import *\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from collections import Counter \n",
    "import collections\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "#Functionality to turn stemming on or off\n",
    "STEMMING = True  # judgment call, parsed documents more readable if False\n",
    "MAX_NGRAM_LENGTH = 1  # try 1 and 2 and see which yields better modeling results\n",
    "VECTOR_LENGTH = 100  # set vector length for TF-IDF and Doc2Vec\n",
    "DISPLAYMAX = 6 # Dispaly count for head() or tail() sorted values\n",
    "DROP_STOPWORDS = False\n",
    "SET_RANDOM = 9999\n",
    "\n",
    "# Display the dataframes side by side\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "CSS = \"\"\"\n",
    ".output {\n",
    "    flex-direction: row;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "HTML('<style>{}</style>'.format(CSS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label(text):\n",
    "    #print(text)\n",
    "    text = text.replace('.html','')\n",
    "    #print(text)\n",
    "    text = text.replace('.htm','')\n",
    "    if 'wired-' in text:\n",
    "        text = text.replace('wired-','w-')\n",
    "    elif 'nhtsa-' in text:\n",
    "        text = text.replace('nhtsa-', 'n-')\n",
    "    elif 'curbed-' in text:\n",
    "        text = text.replace('curbed-','c-')\n",
    "    elif 'theverge-' in text:\n",
    "        text = text.replace('theverge-','v-')\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    regex.sub('', text)\n",
    "    return text[0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(3) Preprocess the text documents, ensuring that unnecessary tags, punctuation, and images are excluded.  \n",
    "def clean_doc(doc):\n",
    "    \"\"\"Return processed tokens for a given document.\"\"\"\n",
    "    # Split into \"words\"\n",
    "    tokens = doc.split()\n",
    "    # Remove punctuation\n",
    "    re_punc = re.compile(f\"[{re.escape(string.punctuation)}]\")\n",
    "    tokens = [re_punc.sub('', word) for word in tokens]\n",
    "    # Remove non-alphabetic tokens\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # Remove short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 4]\n",
    "    # Make tokens lowercase\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    # Remove stop words\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.append(\"would\")\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # lemmatization for plurals  \n",
    "    if STEMMING:   \n",
    "        lem = WordNetLemmatizer()\n",
    "        tokens = [lem.lemmatize(token) for token in tokens]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data\n",
    "labels=[]\n",
    "text_body=[]\n",
    "text_titles = []\n",
    "with open('autonomous_vehicles_safety_corpus.jl') as json_file:\n",
    "     data = json.load(json_file)\n",
    "     for p in data:\n",
    "         text_body.append(p['BODY'])\n",
    "         text_titles.append(p['TITLE'][0:15])\n",
    "         labels.append(create_label(p['FILENAME']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean words and create list of tokens\n",
    "processed_text = []\n",
    "for document in text_body:\n",
    "    processed_text.append(clean_doc(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stitch the clean data \n",
    "final_processed_text = []  \n",
    "for i in processed_text:\n",
    "    temp_DSI=i[0]\n",
    "    for k in range(1,len(i)):\n",
    "        temp_DSI=temp_DSI+' '+i[k]\n",
    "    final_processed_text.append(temp_DSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Analyst Judgement using Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "count vectorization. . .\n",
      "\n",
      "Training count_vectors_training.shape: (849, 100)\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "### Count Vectorization Frequency\n",
    "##############################\n",
    "count_vectorizer = CountVectorizer(ngram_range = (1, MAX_NGRAM_LENGTH), \n",
    "                                   max_features = VECTOR_LENGTH)\n",
    "count_vectors = count_vectorizer.fit_transform(final_processed_text)\n",
    "print('\\ncount vectorization. . .')\n",
    "print('\\nTraining count_vectors_training.shape:', count_vectors.shape)\n",
    "\n",
    "matrixAnalystJudgment = pd.DataFrame(count_vectors.toarray(), columns=count_vectorizer.get_feature_names(), index=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Working on Count vectorization\n",
      "\n",
      "Largest Count vectors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1-Freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terms</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vehicle</th>\n",
       "      <td>11.273263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selfdriving</th>\n",
       "      <td>6.707892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>autonomous</th>\n",
       "      <td>5.518257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>5.103651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>safety</th>\n",
       "      <td>4.186101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technology</th>\n",
       "      <td>4.121319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               A1-Freq\n",
       "Terms                 \n",
       "vehicle      11.273263\n",
       "selfdriving   6.707892\n",
       "autonomous    5.518257\n",
       "company       5.103651\n",
       "safety        4.186101\n",
       "technology    4.121319"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(4) Create document vectors using Approach 1 above. output Document Frequency\n",
    "###############################################################################\n",
    "### Explore CountVectorizer Values\n",
    "###############################################################################\n",
    "print('\\nWorking on Count vectorization')\n",
    "average_CountVectorizer={}\n",
    "for i in matrixAnalystJudgment.columns:\n",
    "    average_CountVectorizer[i]=np.mean(matrixAnalystJudgment[i])\n",
    "\n",
    "average_CountVectorizer_DF = pd.DataFrame(average_CountVectorizer, index = [0]).transpose()\n",
    "\n",
    "average_CountVectorizer_DF.columns=['A1-Freq']\n",
    "\n",
    "#calculate Q1 and Q3 range\n",
    "Q=np.percentile(average_CountVectorizer_DF, 5)\n",
    "Q1=np.percentile(average_CountVectorizer_DF, 25)\n",
    "Q3=np.percentile(average_CountVectorizer_DF, 75)\n",
    "IQR = Q3 - Q1\n",
    "outlier=Q3+(1.5*IQR)\n",
    "\n",
    "#words that exceed the Q3+IQR*1.5\n",
    "outlier_list = average_CountVectorizer_DF[average_CountVectorizer_DF['A1-Freq'] >= outlier]\n",
    "#print(outlier_list.sort_values('CountVectorizer'))\n",
    "\n",
    "sorted_CountVectorizer = average_CountVectorizer_DF.sort_values('A1-Freq', ascending = False)\n",
    "\n",
    "print('\\nLargest Count vectors')\n",
    "sorted_CountVectorizer.index.name = 'Terms'\n",
    "sorted_CountVectorizer.head(DISPLAYMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2. using TF-IDF.\n",
    "# (5) Create document vectors using Approach 2 above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "### Sklearn TFIDF \n",
    "###############################################################################\n",
    "#note the ngram_range will allow you to include multiple-word tokens within the TFIDF matrix\n",
    "#Call Tfidf Vectorizer\n",
    "#print('\\nWorking on TF-IDF vectorization')\n",
    "\n",
    "Tfidf=TfidfVectorizer(ngram_range = (1, MAX_NGRAM_LENGTH), max_features = VECTOR_LENGTH)\n",
    "\n",
    "#fit the vectorizer using final processed documents.  The vectorizer requires the \n",
    "#stiched back together document.\n",
    "\n",
    "TFIDF_matrix=Tfidf.fit_transform(final_processed_text)     \n",
    "\n",
    "#creating datafram from TFIDF Matrix\n",
    "matrix=pd.DataFrame(TFIDF_matrix.toarray(), columns = Tfidf.get_feature_names(), index = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "### Explore TFIDF Values\n",
    "###############################################################################\n",
    "average_TFIDF={}\n",
    "for i in matrix.columns:\n",
    "    average_TFIDF[i]=np.mean(matrix[i])\n",
    "\n",
    "average_TFIDF_DF = pd.DataFrame(average_TFIDF, index = [0]).transpose()\n",
    "\n",
    "average_TFIDF_DF.columns=['TFIDF-Freq']\n",
    "\n",
    "#calculate Q1 and Q3 range\n",
    "\n",
    "Q1=np.percentile(average_TFIDF_DF, 25)\n",
    "Q3=np.percentile(average_TFIDF_DF, 75)\n",
    "IQR = Q3 - Q1\n",
    "outlier=Q3+(1.5*IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest TF-IDF vectors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TFIDF-Freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terms</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vehicle</th>\n",
       "      <td>0.238004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selfdriving</th>\n",
       "      <td>0.161158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>autonomous</th>\n",
       "      <td>0.147179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>0.140209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technology</th>\n",
       "      <td>0.104772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>safety</th>\n",
       "      <td>0.104280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TFIDF-Freq\n",
       "Terms                  \n",
       "vehicle        0.238004\n",
       "selfdriving    0.161158\n",
       "autonomous     0.147179\n",
       "company        0.140209\n",
       "technology     0.104772\n",
       "safety         0.104280"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A2 - showing document frequency\n",
    "#words that exceed the Q3+IQR*1.5\n",
    "outlier_list_TFIDF = average_TFIDF_DF[average_TFIDF_DF['TFIDF-Freq'] >= outlier]\n",
    "#print(outlier_list_TFIDF.sort_values('TFIDF'))\n",
    "sortedTf_IDF = average_TFIDF_DF.sort_values('TFIDF-Freq', ascending = False)\n",
    "sortedTf_IDF.index.name = 'Terms'\n",
    "print('\\nLargest TF-IDF vectors')\n",
    "sortedTf_IDF.head(DISPLAYMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6) Create document vectors using Approach 3 above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "### Doc2Vec Vectorization\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Doc2Vec Work\n",
      "Number of processor cores: 16\n"
     ]
    }
   ],
   "source": [
    "print('Begin Doc2Vec Work')\n",
    "cores = multiprocessing.cpu_count()\n",
    "print(\"Number of processor cores:\", cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Working on Doc2Vec vectorization.\n"
     ]
    }
   ],
   "source": [
    "train_corpus = [TaggedDocument(doc, [i]) for i, doc in enumerate(processed_text)]\n",
    "#print('train_corpus[:2]:', train_corpus[:1])\n",
    "\n",
    "print(\"\\nWorking on Doc2Vec vectorization.\")\n",
    "model_d2v = Doc2Vec(vector_size = VECTOR_LENGTH, window = 4, min_count = 2, workers = cores, epochs = 40)\n",
    "\n",
    "model_d2v.build_vocab(train_corpus)\n",
    "\n",
    "# build vectorization model on training set\n",
    "model_d2v.train(train_corpus, total_examples = model_d2v.corpus_count, epochs = model_d2v.epochs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2VecToList = []\n",
    "for word, vocab_obj in model_d2v.wv.vocab.items():\n",
    "    doc2VecToList.append([word,vocab_obj.count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A3-Doc2Vec-Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terms</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>driver</th>\n",
       "      <td>2525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technology</th>\n",
       "      <td>3499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vehicle</th>\n",
       "      <td>9571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>safety</th>\n",
       "      <td>3554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>system</th>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>autonomous</th>\n",
       "      <td>4685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selfdriving</th>\n",
       "      <td>5695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human</th>\n",
       "      <td>2094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crash</th>\n",
       "      <td>1722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>2178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transportation</th>\n",
       "      <td>1830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testing</th>\n",
       "      <td>2505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>4333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public</th>\n",
       "      <td>2182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mile</th>\n",
       "      <td>1737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>street</th>\n",
       "      <td>1727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waymo</th>\n",
       "      <td>2057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                A3-Doc2Vec-Count\n",
       "Terms                           \n",
       "driver                      2525\n",
       "technology                  3499\n",
       "vehicle                     9571\n",
       "safety                      3554\n",
       "system                      1960\n",
       "autonomous                  4685\n",
       "selfdriving                 5695\n",
       "human                       2094\n",
       "crash                       1722\n",
       "people                      2178\n",
       "transportation              1830\n",
       "testing                     2505\n",
       "company                     4333\n",
       "public                      2182\n",
       "mile                        1737\n",
       "street                      1727\n",
       "waymo                       2057"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_doc2_vec = pd.DataFrame(doc2VecToList, columns=['Terms', 'A3-Doc2Vec-Count'])\n",
    "df_doc2_vec.set_index('Terms', inplace=True)\n",
    "df_doc2_vec[df_doc2_vec['A3-Doc2Vec-Count'] > 1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doc2Vec =df_doc2_vec.sort_values('A3-Doc2Vec-Count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(7) Compare results across the three approaches. \n",
    "#      In comparing Approach 1 with Approach 2, for example, \n",
    "#       find the two or three terms (nouns/noun phrases) \n",
    "#       from your documents that you thought to be important/prevalent \n",
    "#       from Approach 1 and see if they did indeed have the highest TF-IDF \n",
    "#       as shown in the results from Approach 2. \n",
    "#       Similarly, find two or three terms that you thought would have a lower importance/prevalence, \n",
    "#       and see if that bears out. \n",
    "#     Judge the degree of agreement across the approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1-Freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terms</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vehicle</th>\n",
       "      <td>11.273263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selfdriving</th>\n",
       "      <td>6.707892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>autonomous</th>\n",
       "      <td>5.518257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>5.103651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>safety</th>\n",
       "      <td>4.186101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technology</th>\n",
       "      <td>4.121319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               A1-Freq\n",
       "Terms                 \n",
       "vehicle      11.273263\n",
       "selfdriving   6.707892\n",
       "autonomous    5.518257\n",
       "company       5.103651\n",
       "safety        4.186101\n",
       "technology    4.121319"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TFIDF-Freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terms</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vehicle</th>\n",
       "      <td>0.238004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selfdriving</th>\n",
       "      <td>0.161158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>autonomous</th>\n",
       "      <td>0.147179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>0.140209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technology</th>\n",
       "      <td>0.104772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>safety</th>\n",
       "      <td>0.104280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TFIDF-Freq\n",
       "Terms                  \n",
       "vehicle        0.238004\n",
       "selfdriving    0.161158\n",
       "autonomous     0.147179\n",
       "company        0.140209\n",
       "technology     0.104772\n",
       "safety         0.104280"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A3-Doc2Vec-Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terms</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vehicle</th>\n",
       "      <td>9571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selfdriving</th>\n",
       "      <td>5695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>autonomous</th>\n",
       "      <td>4685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>4333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>safety</th>\n",
       "      <td>3554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technology</th>\n",
       "      <td>3499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             A3-Doc2Vec-Count\n",
       "Terms                        \n",
       "vehicle                  9571\n",
       "selfdriving              5695\n",
       "autonomous               4685\n",
       "company                  4333\n",
       "safety                   3554\n",
       "technology               3499"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sorted_CountVectorizer.head(DISPLAYMAX))\n",
    "display(sortedTf_IDF.head(DISPLAYMAX))\n",
    "display(df_doc2Vec.head(DISPLAYMAX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(7) Similarly, find two or three terms that  \n",
    "#    you thought would have a lower importance/prevalence,and see if that bears out. \n",
    "#    Judge the degree of agreement across the approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1-Freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terms</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>engineer</th>\n",
       "      <td>0.620730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transit</th>\n",
       "      <td>0.619552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy</th>\n",
       "      <td>0.619552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electric</th>\n",
       "      <td>0.613663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better</th>\n",
       "      <td>0.612485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rule</th>\n",
       "      <td>0.604240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A1-Freq\n",
       "Terms             \n",
       "engineer  0.620730\n",
       "transit   0.619552\n",
       "policy    0.619552\n",
       "electric  0.613663\n",
       "better    0.612485\n",
       "rule      0.604240"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TFIDF-Freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terms</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>question</th>\n",
       "      <td>0.024738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rule</th>\n",
       "      <td>0.024702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>government</th>\n",
       "      <td>0.024479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>driven</th>\n",
       "      <td>0.023059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standard</th>\n",
       "      <td>0.022549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy</th>\n",
       "      <td>0.020624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            TFIDF-Freq\n",
       "Terms                 \n",
       "question      0.024738\n",
       "rule          0.024702\n",
       "government    0.024479\n",
       "driven        0.023059\n",
       "standard      0.022549\n",
       "policy        0.020624"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A3-Doc2Vec-Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terms</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>star</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>telemetry</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canceling</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techified</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accordingly</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>innovating</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             A3-Doc2Vec-Count\n",
       "Terms                        \n",
       "star                        2\n",
       "telemetry                   2\n",
       "canceling                   2\n",
       "techified                   2\n",
       "accordingly                 2\n",
       "innovating                  2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sorted_CountVectorizer.tail(DISPLAYMAX))\n",
    "display(sortedTf_IDF.tail(DISPLAYMAX))\n",
    "display(df_doc2Vec.tail(DISPLAYMAX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#safetyCount = 0\n",
    "#techCount = 0\n",
    "#for text in final_processed_text:\n",
    "#    safety = len(re.findall('safety',text))\n",
    "#    technology = len(re.findall('technology',text))\n",
    "#    crash = len(re.findall('crash',text))\n",
    "#    ls1 = [safety, technology]\n",
    "#    m = max(ls1)\n",
    "#    if safety == m:\n",
    "#        safetyCount += 1\n",
    "#    elif technology == m:\n",
    "#        techCount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(safetyCount, techCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#safetyCount = 0\n",
    "#techCount = 0\n",
    "#counter = 0\n",
    "#for text in final_processed_text:\n",
    "#    safety = len(re.findall('safety',text))\n",
    "#    technology = len(re.findall('technology',text))\n",
    "#    crash = len(re.findall('crash',text))\n",
    "#    if crash > 0 and safety == technology:\n",
    "#        print('Doc index[' + str(counter) + '], safety: ' + str(safety) + ', technology: '+ str(technology) \\\n",
    "#                + ', crash: ' + str(crash))\n",
    "#    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#safetyCount = 0\n",
    "#techCount = 0\n",
    "#counter = 0\n",
    "#for text in final_processed_text:\n",
    "#    safety = len(re.findall('safety',text))\n",
    "#    technology = len(re.findall('technology',text))\n",
    "#    crash = len(re.findall('crash',text))\n",
    "#    people = len(re.findall('people',text))\n",
    "#    driver = len(re.findall('driver',text))\n",
    "#    human= len(re.findall('human',text))\n",
    "#    lidar= len(re.findall('lidar',text))\n",
    "#    autonomous= len(re.findall('autonomous',text))\n",
    "#    research = len(re.findall('research',text))\n",
    "#    selfdriving  = len(re.findall('selfdriving',text))\n",
    "#    policy  = len(re.findall('policy ',text))\n",
    "#    if  safety == technology and safety == 0 and crash == 0 and people == 0 and human == 0 and driver == 0 \\\n",
    "#    and lidar == 0 and autonomous == 0 and research == 0 and selfdriving == 0  and policy == 0:\n",
    "#        print('Doc index[' + str(counter) + '], safety: ' + str(safety) + ', technology: '+ str(technology) + \\\n",
    "#               ',  crash: ' + str(crash) + ', people: ' + str(people) + ', human: ' + str(human) \\\n",
    "#               + ', driver: ' + str(driver) + ', lidar: ' + str(lidar) + ', autonomous: ' + str(autonomous) + \\\n",
    "#               ', research: ' + str(research) + ', selfdriving:' + str(selfdriving) +\\\n",
    "#                + ', policy: ' + policy)\n",
    "#    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safety Count:334, Technology Count:515, Equal Count:0\n"
     ]
    }
   ],
   "source": [
    "safetyCount = 0\n",
    "techCount = 0\n",
    "counter = 0\n",
    "equal = 0\n",
    "for text in final_processed_text:\n",
    "    safety = len(re.findall('safety',text))\n",
    "    technology = len(re.findall('technology',text))\n",
    "    crash = len(re.findall('crash',text))\n",
    "    people = len(re.findall('people',text))\n",
    "    driver = len(re.findall('driver',text))\n",
    "    human= len(re.findall('human',text))\n",
    "    lidar= len(re.findall('lidar',text))\n",
    "    autonomous= len(re.findall('autonomous',text))\n",
    "    research = len(re.findall('research',text))\n",
    "    selfdriving  = len(re.findall('selfdriving ',text))\n",
    "    policy  = len(re.findall('policy ',text))\n",
    "    standard  = len(re.findall('standard ',text))\n",
    "    rule  = len(re.findall('rule ',text))\n",
    "    government = len(re.findall('government ',text))\n",
    "    testing = len(re.findall('testing ',text))\n",
    "    electric  = len(re.findall('electric ',text))\n",
    "    engineer  = len(re.findall('engineer ',text))\n",
    "    system  = len(re.findall('system ',text))    \n",
    "    \n",
    "    s = safety + crash + people + driver + human + policy + standard + rule + government + testing\n",
    "    t = technology + lidar + autonomous + research + selfdriving + electric + engineer +  system\n",
    "    if s > t: \n",
    "       safetyCount +=1\n",
    "    elif s < t:\n",
    "       techCount += 1\n",
    "    elif s == t:\n",
    "        # if equal becomes safety\n",
    "        safetyCount +=1\n",
    "    #print('Doc index[' + str(counter) + '], safety: ' + str(s) + ', technology: '+ str(t))\n",
    "    counter +=1\n",
    "    \n",
    "print('Safety Count:' + str(safetyCount) + ', Technology Count:' + str(techCount) + ', Equal Count:' + str(equal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manually</th>\n",
       "      <th>Derived</th>\n",
       "      <th>Equivalent</th>\n",
       "      <th>Terms</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class Terms</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>safety</th>\n",
       "      <td>safety</td>\n",
       "      <td>crash</td>\n",
       "      <td>people</td>\n",
       "      <td>driver</td>\n",
       "      <td>human</td>\n",
       "      <td>policy</td>\n",
       "      <td>standard</td>\n",
       "      <td>rule</td>\n",
       "      <td>government</td>\n",
       "      <td>testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technology</th>\n",
       "      <td>technology</td>\n",
       "      <td>lidar</td>\n",
       "      <td>autonomous</td>\n",
       "      <td>research</td>\n",
       "      <td>selfdriving</td>\n",
       "      <td>electric</td>\n",
       "      <td>engineer</td>\n",
       "      <td>system</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Manually Derived  Equivalent     Terms                         \\\n",
       "Class Terms                                                                    \n",
       "safety           safety   crash      people    driver        human    policy   \n",
       "technology   technology   lidar  autonomous  research  selfdriving  electric   \n",
       "\n",
       "                                                    \n",
       "Class Terms                                         \n",
       "safety       standard    rule  government  testing  \n",
       "technology   engineer  system                       "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manualclassTermsEquivalents = [['safety', 'crash','people','driver','human','policy', 'standard', 'rule','government',\\\n",
    "                                'testing'],\n",
    "                               ['technology','lidar','autonomous','research','selfdriving','electric','engineer','system',\\\n",
    "                                '','']]\n",
    "manualLabels = pd.DataFrame(data =manualclassTermsEquivalents, index=['safety','technology'],\\\n",
    "                            columns=['Manually','Derived','Equivalent','Terms','','','','','',''])\n",
    "manualLabels.index.name ='Class Terms'\n",
    "manualLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
