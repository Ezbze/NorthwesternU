{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MSDS462_Module3_Demo1_AzureCV_ImageAnalysis","provenance":[{"file_id":"1K2mlYCaL72sEELPSSDhC-tlmfL9B78LF","timestamp":1618181525134}],"collapsed_sections":[],"authorship_tag":"ABX9TyM05sCEP0bpEw4NPlRhdNZo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"BD_SkRJhIT0Z"},"source":["###Module 3 Demo Video Assignment\n","\n","Create and share a Colab notebook that uses a cloud computer vision API or a Github gist (Links to an external site.) where the API is called in a script.  Create and share a 30-second demo video of this notebook.\n","\n","1. Create the Resource Group, \n","2. Get the Url and Key\n","3. Install azure cognitive services vision computer vision\n","4. Install Pillow\n","5. Import libraries\n","6. Define the subscription key and url variables\n","7. Get An Image Decription, Category and Tags\n","8. Detect objects, Brands and Faces\n","9. Detect adult, racy, or gory content\n","\n","\n","I am using Azure Cognitive services image analysis endpoint from  [Image Analysis documentation.](https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/quickstarts-sdk/image-analysis-client-library?tabs=visual-studio&pivots=programming-language-python)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NDHadh8jIxmi"},"source":["###Setup\n","\n","Install Dependencies and import libraries"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pbjLlVUNI23R","executionInfo":{"status":"ok","timestamp":1618183017470,"user_tz":300,"elapsed":3054,"user":{"displayName":"Ezana Beyenne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisqw8dp3Kg67wB7kgFfxdMn_5XXF4r6jlIyIjG=s64","userId":"05782892023718671809"}},"outputId":"3b37ffd9-a44b-4ab5-c892-ac452eddf687"},"source":["pip install --upgrade azure-cognitiveservices-vision-computervision"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: azure-cognitiveservices-vision-computervision in /usr/local/lib/python3.7/dist-packages (0.8.0)\n","Requirement already satisfied, skipping upgrade: azure-common~=1.1 in /usr/local/lib/python3.7/dist-packages (from azure-cognitiveservices-vision-computervision) (1.1.27)\n","Requirement already satisfied, skipping upgrade: msrest>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from azure-cognitiveservices-vision-computervision) (0.6.21)\n","Requirement already satisfied, skipping upgrade: requests~=2.16 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.23.0)\n","Requirement already satisfied, skipping upgrade: isodate>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (0.6.0)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.3.0)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.0.4)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.10)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.24.3)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from isodate>=0.6.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.15.0)\n","Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zXc_AbXyJIMw","executionInfo":{"status":"ok","timestamp":1618183024932,"user_tz":300,"elapsed":3066,"user":{"displayName":"Ezana Beyenne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisqw8dp3Kg67wB7kgFfxdMn_5XXF4r6jlIyIjG=s64","userId":"05782892023718671809"}},"outputId":"12710e60-465e-4492-d98b-e0136835b049"},"source":["pip install pillow"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"anJM9GuVJTMD"},"source":["from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n","from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n","from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n","from msrest.authentication import CognitiveServicesCredentials\n","\n","from array import array\n","import os\n","from PIL import Image\n","import sys\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_gvtKKCrKvgZ","executionInfo":{"status":"ok","timestamp":1618183040186,"user_tz":300,"elapsed":221,"user":{"displayName":"Ezana Beyenne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisqw8dp3Kg67wB7kgFfxdMn_5XXF4r6jlIyIjG=s64","userId":"05782892023718671809"}}},"source":["subscription_key = \"\"\n","endpoint = \"\""],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ad7N-a9LK3S-","executionInfo":{"status":"ok","timestamp":1618183045125,"user_tz":300,"elapsed":206,"user":{"displayName":"Ezana Beyenne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisqw8dp3Kg67wB7kgFfxdMn_5XXF4r6jlIyIjG=s64","userId":"05782892023718671809"}}},"source":["computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6EFqd0H5K-zs"},"source":["##Get image description\n","\n","Describe an Image - remote\n","This example describes the contents of an image with the confidence score.\n","\n","<figure>\n","<center>\n","<img src='https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg' />\n","<figcaption>Landmark.jpg used below</figcaption></center>\n","</figure>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F7pvUIZiLBDC","executionInfo":{"status":"ok","timestamp":1618183086300,"user_tz":300,"elapsed":2413,"user":{"displayName":"Ezana Beyenne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisqw8dp3Kg67wB7kgFfxdMn_5XXF4r6jlIyIjG=s64","userId":"05782892023718671809"}},"outputId":"13196fb6-2f2f-4cf4-f76a-cbd6e0aae4aa"},"source":["remote_image_url = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg\"\n","print(\"===== Describe an image - remote =====\")\n","# Call API\n","description_results = computervision_client.describe_image(remote_image_url )\n","\n","# Get the captions (descriptions) from the response, with confidence level\n","print(\"Description of remote image: \")\n","if (len(description_results.captions) == 0):\n","    print(\"No description detected.\")\n","else:\n","    for caption in description_results.captions:\n","        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["===== Describe an image - remote =====\n","Description of remote image: \n","'a large stone structure with many arches with Colosseum in the background' with confidence 26.39%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nZ3gNVKeLJ3g"},"source":["## Get image category\n","Categorize an Image - remote\n","This example extracts (general) categories from a remote image with a confidence score.\n","\n","<figure>\n","<center>\n","<img src='https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg' />\n","<figcaption>Landmark.jpg used below</figcaption></center>\n","</figure>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NetoazmkLHrg","executionInfo":{"status":"ok","timestamp":1618183147281,"user_tz":300,"elapsed":530,"user":{"displayName":"Ezana Beyenne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisqw8dp3Kg67wB7kgFfxdMn_5XXF4r6jlIyIjG=s64","userId":"05782892023718671809"}},"outputId":"2df499ff-62be-4fb8-b1bf-3fd09d23d7e9"},"source":["remote_image_url = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg\"\n","print(\"===== Categorize an image - remote =====\")\n","# Select the visual feature(s) you want.\n","remote_image_features = [\"categories\"]\n","# Call API with URL and features\n","categorize_results_remote = computervision_client.analyze_image(remote_image_url , remote_image_features)\n","\n","# Print results with confidence score\n","print(\"Categories from remote image: \")\n","if (len(categorize_results_remote.categories) == 0):\n","    print(\"No categories detected.\")\n","else:\n","    for category in categorize_results_remote.categories:\n","        print(\"'{}' with confidence {:.2f}%\".format(category.name, category.score * 100))"],"execution_count":26,"outputs":[{"output_type":"stream","text":["===== Categorize an image - remote =====\n","Categories from remote image: \n","'building_' with confidence 31.64%\n","'others_' with confidence 0.39%\n","'outdoor_' with confidence 3.91%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HxKsbvqkLP57"},"source":["## Get image tags\n","Tag an Image - remote\n","This example returns a tag (key word) for each thing in the image.\n","\n","<figure>\n","<center>\n","<img src='https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg' />\n","<figcaption>Landmark.jpg used below</figcaption></center>\n","</figure>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GnPGX4HiLSj7","executionInfo":{"status":"ok","timestamp":1618183190376,"user_tz":300,"elapsed":774,"user":{"displayName":"Ezana Beyenne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisqw8dp3Kg67wB7kgFfxdMn_5XXF4r6jlIyIjG=s64","userId":"05782892023718671809"}},"outputId":"470629d6-3359-40e4-a4fd-00f818cce8fa"},"source":["remote_image_url = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg\"\n","print(\"===== Tag an image - remote =====\")\n","# Call API with remote image\n","tags_result_remote = computervision_client.tag_image(remote_image_url )\n","\n","# Print results with confidence score\n","print(\"Tags in the remote image: \")\n","if (len(tags_result_remote.tags) == 0):\n","    print(\"No tags detected.\")\n","else:\n","    for tag in tags_result_remote.tags:\n","        print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["===== Tag an image - remote =====\n","Tags in the remote image: \n","'outdoor' with confidence 99.00%\n","'building' with confidence 98.81%\n","'sky' with confidence 98.21%\n","'stadium' with confidence 98.17%\n","'ancient rome' with confidence 96.16%\n","'ruins' with confidence 95.04%\n","'amphitheatre' with confidence 93.99%\n","'ancient roman architecture' with confidence 92.65%\n","'historic site' with confidence 89.55%\n","'ancient history' with confidence 89.54%\n","'history' with confidence 86.72%\n","'archaeological site' with confidence 84.41%\n","'travel' with confidence 65.85%\n","'large' with confidence 61.02%\n","'city' with confidence 56.57%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ldWoDLjrLWag"},"source":["##Detect objects\n","\n","Detect Objects - remote\n","This example detects different kinds of objects with bounding boxes in a remote image.\n","\n","<figure>\n","<center>\n","<img src='https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/objects.jpg' />\n","<figcaption>Skateboarder</figcaption></center>\n","</figure>\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iJE4OwbYLYdu","executionInfo":{"status":"ok","timestamp":1618183240300,"user_tz":300,"elapsed":520,"user":{"displayName":"Ezana Beyenne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisqw8dp3Kg67wB7kgFfxdMn_5XXF4r6jlIyIjG=s64","userId":"05782892023718671809"}},"outputId":"1a53103c-c830-4f72-c4c0-e55a5352c937"},"source":["remote_image_url_objects = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/objects.jpg\"\n","print(\"===== Detect Objects - remote =====\")\n","# Get URL image with different objects\n","# Call API with URL\n","detect_objects_results_remote = computervision_client.detect_objects(remote_image_url_objects)\n","\n","# Print detected objects results with bounding boxes\n","print(\"Detecting objects in remote image:\")\n","if len(detect_objects_results_remote.objects) == 0:\n","    print(\"No objects detected.\")\n","else:\n","    for object in detect_objects_results_remote.objects:\n","        print(\"object at location {}, {}, {}, {}\".format( \\\n","        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n","        object.rectangle.y, object.rectangle.y + object.rectangle.h))"],"execution_count":28,"outputs":[{"output_type":"stream","text":["===== Detect Objects - remote =====\n","Detecting objects in remote image:\n","object at location 213, 365, 85, 208\n","object at location 218, 402, 179, 384\n","object at location 238, 417, 298, 416\n","object at location 116, 419, 60, 386\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Y5Q0nAfhLd63"},"source":["## Detect brands\n","\n","Detect Brands - remote\n","This example detects common brands like logos and puts a bounding box around them.\n","\n","<figure>\n","<center>\n","<img src='https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/images/gray-shirt-logo.jpg' />\n","<figcaption>Gray MSFT Shirt with Logo</figcaption></center>\n","</figure>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ix0AH5sGLkBw","executionInfo":{"status":"ok","timestamp":1618183326070,"user_tz":300,"elapsed":653,"user":{"displayName":"Ezana Beyenne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisqw8dp3Kg67wB7kgFfxdMn_5XXF4r6jlIyIjG=s64","userId":"05782892023718671809"}},"outputId":"cd85d0f4-3139-4705-cb41-f9e568560158"},"source":["# Get a URL with a brand logo\n","remote_image_url = \"https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/images/gray-shirt-logo.jpg\"\n","print(\"===== Detect Brands - remote =====\")\n","# Select the visual feature(s) you want\n","remote_image_features = [\"brands\"]\n","# Call API with URL and features\n","detect_brands_results_remote = computervision_client.analyze_image(remote_image_url, remote_image_features)\n","\n","print(\"Detecting brands in remote image: \")\n","if len(detect_brands_results_remote.brands) == 0:\n","    print(\"No brands detected.\")\n","else:\n","    for brand in detect_brands_results_remote.brands:\n","        print(\"'{}' brand detected with confidence {:.1f}% at location {}, {}, {}, {}\".format( \\\n","        brand.name, brand.confidence * 100, brand.rectangle.x, brand.rectangle.x + brand.rectangle.w, \\\n","        brand.rectangle.y, brand.rectangle.y + brand.rectangle.h))"],"execution_count":29,"outputs":[{"output_type":"stream","text":["===== Detect Brands - remote =====\n","Detecting brands in remote image: \n","'Microsoft' brand detected with confidence 62.5% at location 58, 113, 106, 152\n","'Microsoft' brand detected with confidence 69.8% at location 58, 260, 86, 149\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2ldqrdFlNWvJ"},"source":["## Detect faces\n","Detect Faces - remote\n","This example detects faces in a remote image, gets their gender and age, \n","and marks them with a bounding box.\n","\n","\n","<figure>\n","<center>\n","<img src='https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/faces.jpg' />\n","<figcaption>Faces</figcaption></center>\n","</figure>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g7QEJDxpLqQo","executionInfo":{"status":"ok","timestamp":1618183370109,"user_tz":300,"elapsed":1261,"user":{"displayName":"Ezana Beyenne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisqw8dp3Kg67wB7kgFfxdMn_5XXF4r6jlIyIjG=s64","userId":"05782892023718671809"}},"outputId":"43c6e627-53c3-4d60-9cf4-c8c20aeeafe9"},"source":["# Get an image with faces\n","remote_image_url_faces = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/faces.jpg\"\n","print(\"===== Detect Faces - remote =====\")\n","\n","# Select the visual feature(s) you want.\n","remote_image_features = [\"faces\"]\n","# Call the API with remote URL and features\n","detect_faces_results_remote = computervision_client.analyze_image(remote_image_url_faces, remote_image_features)\n","\n","# Print the results with gender, age, and bounding box\n","print(\"Faces in the remote image: \")\n","if (len(detect_faces_results_remote.faces) == 0):\n","    print(\"No faces detected.\")\n","else:\n","    for face in detect_faces_results_remote.faces:\n","        print(\"'{}' of age {} at location {}, {}, {}, {}\".format(face.gender, face.age, \\\n","        face.face_rectangle.left, face.face_rectangle.top, \\\n","        face.face_rectangle.left + face.face_rectangle.width, \\\n","        face.face_rectangle.top + face.face_rectangle.height))"],"execution_count":30,"outputs":[{"output_type":"stream","text":["===== Detect Faces - remote =====\n","Faces in the remote image: \n","'Male' of age 39 at location 118, 159, 212, 253\n","'Male' of age 54 at location 492, 111, 582, 201\n","'Female' of age 55 at location 18, 153, 102, 237\n","'Female' of age 33 at location 386, 166, 467, 247\n","'Female' of age 18 at location 235, 158, 311, 234\n","'Female' of age 8 at location 323, 163, 391, 231\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0TrBSweOQFBp"},"source":["###Detect adult, racy, or gory content\n","\n","Detect Adult or Racy Content - remote\n","This example detects adult or racy content in a remote image, then prints the adult/racy score.\n","The score is ranged 0.0 - 1.0 with smaller numbers indicating negative results.\n","\n","<figure>\n","<center>\n","<img src='https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/faces.jpg' />\n","<figcaption>Faces</figcaption></center>\n","</figure>\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KrDPjXi-QNVa","executionInfo":{"status":"ok","timestamp":1618183532499,"user_tz":300,"elapsed":927,"user":{"displayName":"Ezana Beyenne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisqw8dp3Kg67wB7kgFfxdMn_5XXF4r6jlIyIjG=s64","userId":"05782892023718671809"}},"outputId":"8d51b689-35ef-42f6-932d-ad2fa0b9242d"},"source":["# Get an image with faces\n","remote_image_url_faces = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/faces.jpg\"\n","print(\"===== Detect Adult or Racy Content - remote =====\")\n","# Select the visual feature(s) you want\n","remote_image_features = [\"adult\"]\n","# Call API with URL and features\n","detect_adult_results_remote = computervision_client.analyze_image(remote_image_url, remote_image_features)\n","\n","# Print results with adult/racy score\n","print(\"Analyzing remote image for adult or racy content ... \")\n","print(\"Is adult content: {} with confidence {:.2f}\".format(detect_adult_results_remote.adult.is_adult_content, detect_adult_results_remote.adult.adult_score * 100))\n","print(\"Has racy content: {} with confidence {:.2f}\".format(detect_adult_results_remote.adult.is_racy_content, detect_adult_results_remote.adult.racy_score * 100))"],"execution_count":31,"outputs":[{"output_type":"stream","text":["===== Detect Adult or Racy Content - remote =====\n","Analyzing remote image for adult or racy content ... \n","Is adult content: False with confidence 0.66\n","Has racy content: False with confidence 0.83\n"],"name":"stdout"}]}]}